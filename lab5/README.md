# Lab 5

Random forests or random decision forests is an ensemble learning method for classification, regression and other tasks that operates by constructing a multitude of decision trees at training time. For classification tasks, the output of the random forest is the class selected by most trees. For regression tasks, the mean or average prediction of the individual trees is returned.[1][2] Random decision forests correct for decision trees' habit of overfitting to their training set.[3]: 587–588  Random forests generally outperform decision trees, but their accuracy is lower than gradient boosted trees. However, data characteristics can affect their performance.

Implement random forest and ADABooting spam classifiers using the email spam dataset from this baseline code (Links to an external site.).

<img width="627" alt="lab5" src="https://user-images.githubusercontent.com/89316938/167339868-7e5c9315-fc32-4d03-ba7b-eb605c764561.png">
